# Spark中RDD的持久化

Spark中有缓存与检查点两种RDD持久化机制。

- cache：
  - 在内存中进行缓存
  - 不会截断血统
  - 是在使用过程中对常用数据进行缓存
- checkpoint：
  - 在磁盘中进行存储
  - 截断血统
  - 用来设置检查点，对于特别长的DAG，在计算过程中产生数据丢失方便快速恢复
  - 注意：在checkpoint之前必须没有任何任务提交才会生效，checkpoint过程会额外提交一次任务